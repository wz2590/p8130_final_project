---
title: "data_exploration"
author: "Weiheng Zhang"
date: "2021/11/28"
output: github_document
---

```{r message = FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(p8105.datasets)
library(leaflet)
library(mgcv)
library(modelr)
library(corrplot)
library(MASS)
library(performance)
library(leaps)


theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Data cleaning

```{r message = FALSE, warning = FALSE}
cdi =
  read_csv("./data/cdi.csv") %>% 
  mutate(
    cty = as.factor(cty),
    state = as.factor(state),
    region = factor(region, levels = c("1", "2", "3", "4"),
                    labels = c("Northeast", "North_Central", "South", "West")),
    CRM_1000 = 1000*crimes/pop) %>% 
  relocate(CRM_1000)

cdi
```

## Descriptive Statistics.
```{r}
summary(cdi)
```

```{r}
sapply(cdi, function(x) sum(is.na(x)))

map(cdi, ~sum(is.na(.)))
```
No missing values were found.

## Boxplot for each variable

```{r, dpi = 300}
par(mfrow = c(2, 3))
boxplot(cdi$CRM_1000, main = 'Crime Rate per 1000 people') # an obvious outlier around 300
boxplot(cdi$area, main = 'Land Area')
boxplot(cdi$pop,main = 'Total Population')
boxplot(cdi$pop18, main = 'Percent of Population Aged 18-34')
boxplot(cdi$pop65, main = 'Percent of Population Aged 65+')
boxplot(cdi$docs, main = 'Number of Active Physicians')


```

```{r, dpi = 300}
par(mfrow = c(2,4), dpi = 300)
boxplot(cdi$beds, main = 'Number of Hospital Beds')
boxplot(cdi$hsgrad, main = 'Percent High School Graduates')
boxplot(cdi$bagrad, main = 'Percent Bachelor’s Degrees')
boxplot(cdi$poverty, main = 'Percent Below Poverty Level')
boxplot(cdi$unemp, main = 'Percent Unemployment')
boxplot(cdi$pcincome, main = 'Per Capita Income')
boxplot(cdi$totalinc, main = 'Total Personal Income')
```

## Marginal correlation with CRM_1000 of each variable

```{r, dpi = 300}
cdi %>% ggplot(aes(x = area, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pop, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pop18, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = pop65, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = docs, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = beds, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = hsgrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') #negative correlation
cdi %>% ggplot(aes(x = bagrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = poverty, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = unemp, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pcincome, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = totalinc, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = region, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')

```

## Identify counties with unusual crime rates.
```{r}
upper = quantile(cdi$CRM_1000, 0.75)
lower = quantile(cdi$CRM_1000, 0.25)
IQR = upper - lower

cdi %>% 
  filter(CRM_1000 > upper + 1.5*IQR,
         CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(cty, CRM_1000) %>%
  knitr::kable(digits = 2)


boxplot(cdi$CRM_1000, main = 'Crime Rate per 1000 people') 
```


## Group by states and check for outliers again.
```{r}
cdi_state = 
  cdi %>% 
  group_by(state) %>% 
  summarise(state_pop = sum(pop),
            state_crimes = sum(crimes)) %>% 
  mutate(state_CRM_1000 = 1000*state_crimes/state_pop) %>% 
  relocate(state_CRM_1000)

cdi_state
```

```{r}
upper = quantile(cdi_state$state_CRM_1000, 0.75)
lower = quantile(cdi_state$state_CRM_1000, 0.25)
IQR = upper - lower

cdi_state %>% 
  filter(state_CRM_1000 > upper + 1.5*IQR,
         state_CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(state, state_CRM_1000) %>%
  knitr::kable(digits = 2)


boxplot(cdi_state$state_CRM_1000, main = 'State Crime Rate per 1000 people') 

```
  
Surprisingly, if we look at the CRM_1000 at state level, no outlier was found.



## Check for transformation

```{r}
# fit multivariate model
cdi_pred = 
  cdi %>% 
  dplyr::select(-id, -cty, -crimes)

mult.fit1 = lm(CRM_1000 ~ ., data = cdi_pred) 
summary(mult.fit1)

# check diagnostics
plot(mult.fit1)
boxcox(mult.fit1)
```

## a = 1/2. Perform sqrt transformation.

```{r}
cdi_sqrt = 
  cdi_pred %>% 
  mutate(sqrt_CRM_1000 = sqrt(CRM_1000)) %>% 
  dplyr::select(-CRM_1000) %>% 
  relocate(sqrt_CRM_1000)

cdi_sqrt

mult.fit2 = lm(sqrt_CRM_1000 ~ ., data = cdi_sqrt) 

# check diagnostics
summary(mult.fit2) ##region returned NA, why?
boxcox(mult.fit2) 

```


## Checking to Outliers and Influential Points

```{r}
# residuals vs leverage plot
plot(mult.fit1, which = 4)

# remove influential points
cdi_predOut = cdi_pred[-c(1, 6),]

# plot with and without influential points
plot(cdi_pred$poverty, cdi_pred$CRM_1000)
plot(cdi_predOut$poverty, cdi_predOut$CRM_1000)

# fit model with and without influential points
with = lm(CRM_1000 ~ ., data = cdi_pred) 

without = lm(CRM_1000 ~ ., data = cdi_predOut)

summary(with); summary(without) ##比较p value和r squared

# check without diagnostics
plot(without)
```


## check for multicollinearity
```{r, dpi = 300}
cdi_cor = 
  cdi_sqrt %>%
  mutate(
    state = as.numeric(state),
    region = as.numeric(region)
  ) %>% 
  dplyr::select(-sqrt_CRM_1000)

pairs(cdi_cor)
cor(cdi_cor) %>% 
  knitr::kable()

corrplot(cor(cdi_cor), type = "upper", diag = FALSE)
```
Based on the correlation plot, pop is highly correlated with docs, beds, and totalinc; totalinc is highly correlated with docs and beds; hsgrad is highly correlated with bagrad and poverty. 


```{r}
new_cdi =
  cdi_sqrt %>% 
  mutate(
    state = as.numeric(state),
    region = as.numeric(region)
  ) %>% 
  dplyr::select(-id, -cty, -CRM_1000)

pairs(new_cdi)

cor(new_cdi)

corrplot(cor(new_cdi), type = "upper", diag = FALSE)
```


```{r}
mult.fit = lm(sqrt_CRM_1000 ~ ., data = new_cdi)
summary(mult.fit)
check_collinearity(mult.fit)
```

    state = as.factor(state),
    region = as.factor(region))


mult.fit = lm(sqrt_CRM_1000 ~ ., data = new_cdi)
summary(mult.fit)


mult.fit %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Backward Elimination

```{r}
# No region
step1 = update(mult.fit, . ~ . -region)
summary(step1)

# No state
step2 = update(step1, . ~ . -state)
summary(step2)

# No bagrad
step3 = update(step2, . ~ . -bagrad)
summary(step3)

# No area
step4 = update(step3, . ~ . -area)
summary(step4)

# No hsgrad
step5 = update(step4, . ~ . -hsgrad)
summary(step5)

# No pop65
step6 = update(step5, . ~ . -pop65)
summary(step6)

# No docs
step7 = update(step6, . ~ . -docs)
summary(step7)

multi_fit1 = lm(sqrt_CRM_1000 ~ pop + pop18 + beds + poverty + unemp + pcincome + totalinc + pop * beds + pop * totalinc + beds * totalinc, data = new_cdi)
summary(multi_fit1)

# just use one function
step(mult.fit, direction = 'backward')
step

multi_fit2 = lm(sqrt_CRM_1000 ~ state + area + pop + pop18 + pop65 + beds + bagrad + poverty + pcincome + totalinc + pop * beds + pop * totalinc + beds * totalinc, data = new_cdi)
summary(multi_fit2)
```


Forward Selection
```{r}
mod_select = step(mult.fit, direction = 'backward')
mod_select_1 = step(mult.fit, direction = 'forward')
```

```{r}
our_new_model = lm(sqrt_CRM_1000 ~ area + pop18 + pop65 + beds + crimes + bagrad + 
    poverty + pcincome + totalinc + region, data = new_cdi)
#Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
fit1 = lm(sqrt_CRM_1000 ~ state, data = new_cdi)
summary(fit1)
fit2 = lm(sqrt_CRM_1000 ~ area, data = new_cdi)
summary(fit2)
fit3 = lm(sqrt_CRM_1000 ~ pop, data = new_cdi)
summary(fit3)
fit4 = lm(sqrt_CRM_1000 ~ pop18, data = new_cdi)
summary(fit4)
fit5 = lm(sqrt_CRM_1000 ~ pop65, data = new_cdi)
summary(fit5)
fit6 = lm(sqrt_CRM_1000 ~ docs, data = new_cdi)
summary(fit6)
fit7 = lm(sqrt_CRM_1000 ~ beds, data = new_cdi)
summary(fit7)
fit8 = lm(sqrt_CRM_1000 ~ hsgrad, data = new_cdi)
summary(fit8)
fit9 = lm(sqrt_CRM_1000 ~ bagrad, data = new_cdi)
summary(fit9)
fit10 = lm(sqrt_CRM_1000 ~ poverty, data = new_cdi)
summary(fit10)
fit11 = lm(sqrt_CRM_1000 ~ unemp, data = new_cdi)
summary(fit11)
fit12 = lm(sqrt_CRM_1000 ~ pcincome, data = new_cdi)
summary(fit12)
fit13 = lm(sqrt_CRM_1000 ~ totalinc, data = new_cdi)
summary(fit13)


# Enter first the one with the lowest p-value: poverty
forward1 = lm(sqrt_CRM_1000 ~ poverty, data = new_cdi)
summary(forward1)

### Step 2: Enter the one with the lowest p-value in the rest 
fit1 = update(forward1, . ~ . +state)
summary(fit1)
fit2 = update(forward1, . ~ . +area)
summary(fit2)
fit3 = update(forward1, . ~ . +pop)
summary(fit3)
fit4 = update(forward1, . ~ . +pop18)
summary(fit4)
fit5 = update(forward1, . ~ . +pop65)
summary(fit5)
fit6 = update(forward1, . ~ . +docs)
summary(fit6)
fit7 = update(forward1, . ~ . +beds)
summary(fit7)
fit8 = update(forward1, . ~ . +hsgrad)
summary(fit8)
fit9 = update(forward1, . ~ . +bagrad)
summary(fit9)
fit10 = update(forward1, . ~ . +unemp)
summary(fit10)
fit11 = update(forward1, . ~ . +pcincome)
summary(fit11)
fit12 = update(forward1, . ~ . +totalinc)
summary(fit12)


# Enter the one with the lowest p-value: beds
forward2 = update(forward1, . ~ . + beds)
summary(forward2)

### Step 3: Enter the one with the lowest p-value in the rest 
fit1 = update(forward2, . ~ . +state)
summary(fit1)
fit2 = update(forward2, . ~ . +area)
summary(fit2)
fit3 = update(forward2, . ~ . +pop)
summary(fit3)
fit4 = update(forward2, . ~ . +pop18)
summary(fit4)
fit5 = update(forward2, . ~ . +pop65)
summary(fit5)
fit6 = update(forward2, . ~ . +docs)
summary(fit6)
fit7 = update(forward2, . ~ . +hsgrad)
summary(fit7)
fit8 = update(forward2, . ~ . +bagrad)
summary(fit8)
fit9 = update(forward2, . ~ . +unemp)
summary(fit9)
fit10 = update(forward2, . ~ . +pcincome)
summary(fit10)
fit11 = update(forward2, . ~ . +totalinc)
summary(fit11)


# Enter the one with the lowest p-value: bagrad
forward3 = update(forward2, . ~ . + bagrad)
summary(forward3)

### Step 4: Enter the one with the lowest p-value in the rest 
fit1 = update(forward2, . ~ . +state)
summary(fit1)
fit2 = update(forward2, . ~ . +area)
summary(fit2)
fit3 = update(forward2, . ~ . +pop)
summary(fit3)
fit4 = update(forward2, . ~ . +pop18)
summary(fit4)
fit5 = update(forward2, . ~ . +pop65)
summary(fit5)
fit6 = update(forward2, . ~ . +docs)
summary(fit6)
fit7 = update(forward2, . ~ . +hsgrad)
summary(fit7)
fit8 = update(forward2, . ~ . +unemp)
summary(fit8)
fit9 = update(forward2, . ~ . +pcincome)
summary(fit9)
fit10 = update(forward2, . ~ . +totalinc)
summary(fit10)


# Enter the one with the lowest p-value: unemp
forward4 = update(forward3, . ~ . + unemp)
summary(forward4)


### Step 5: Enter the one with the lowest p-value in the rest 
fit1 = update(forward2, . ~ . +state)
summary(fit1)
fit2 = update(forward2, . ~ . +area)
summary(fit2)
fit3 = update(forward2, . ~ . +pop)
summary(fit3)
fit4 = update(forward2, . ~ . +pop18)
summary(fit4)
fit5 = update(forward2, . ~ . +pop65)
summary(fit5)
fit6 = update(forward2, . ~ . +docs)
summary(fit6)
fit7 = update(forward2, . ~ . +hsgrad)
summary(fit7)
fit8 = update(forward2, . ~ . +pcincome)
summary(fit8)
fit9 = update(forward2, . ~ . +totalinc)
summary(fit9)

# Enter the one with the lowest p-value: pop18

forward5 = update(forward4, . ~ . + pop18)
summary(forward5)

# fit using one function
step(mult.fit, direction = 'forward')
```

>>>>>>> ea3258c2e78405d84f6733a6bc1289b51c133da1

Test Based Procedures

```{r}
new_cdi = 
  new_cdi %>% 

  dplyr::select(sqrt_CRM_1000, area , pop18 , pop65 , beds , crimes , bagrad , 
    poverty , pcincome , totalinc , region)

  mutate(state = as.numeric(state),
         region = as.numeric(region))

mat = as.matrix(new_cdi)
# Printing the 2 best models of each size, using the Cp criterion:
leaps(x = mat[,2:15], y = mat[,1], nbest = 2, method = "Cp")

cv_mod = 
  cv_mod %>% 
  mutate(
    model_1  = map(train, ~lm(sqrt_CRM_1000 ~ area + pop18 + pop65 + beds + crimes + bagrad + 
    poverty + pcincome + totalinc + region, data = .x))) %>%
  mutate(
    rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x)))

# Printing the 2 best models of each size, using the adjusted R^2 criterion:
leaps(x = mat[,2:15], y = mat[,1], nbest = 2, method = "adjr2")


# Function regsubsets() performs a subset selection by identifying the "best" model that contains
# a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better)
b = regsubsets(sqrt_CRM_1000 ~ ., data = new_cdi)
rs = summary(b)

# plot of Cp and Adj-R2 as functions of parameters
par(mfrow = c(1,2))

plot(2:9, rs$cp, xlab ="No of parameters", ylab ="Cp Statistic")
abline(0,1)

plot(2:9, rs$adjr2, xlab ="No of parameters", ylab ="Adj R2")
```

fit models
```{r}
cp_fit1 = lm(sqrt_CRM_1000 ~ area + pop + pop18 + beds + poverty + totalinc + region, data = new_cdi)
summary(cp_fit1)
```







