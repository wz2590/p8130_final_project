---
title: "P8130 Final Project"
authors: Weiheng Zhang, Lin Yang, Yihan Qiu, Fei Sun, Zhuolun Huang
output: github_document
---

```{r, message = FALSE, include = FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(leaflet)
library(corrplot)
library(MASS)
library(performance)
library(leaps)
library(glmnet)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Data cleaning

```{r message = FALSE, warning = FALSE}
cdi =
  read_csv("./data/cdi.csv") %>% 
  mutate(
    cty = as.factor(cty),
    state = as.factor(state),
    region = factor(region, levels = c("1", "2", "3", "4"),
                    labels = c("Northeast", "North_Central", "South", "West")),
    CRM_1000 = 1000*crimes/pop,
    pop_den = pop/area,
    pdocs = 100 * docs/pop,
    pbeds = 100 * beds/pop) %>%
  dplyr::select(-id, -area, -beds, -docs) %>%  # pop and crimes will be removed after detecting state outliers.
  relocate(CRM_1000)

cdi
```

## Descriptive Statistics.
```{r}
summary(cdi)
```

```{r}
sapply(cdi, function(x) sum(is.na(x)))
```
No missing values were found.


Boxplots for each variable
```{r, dpi = 300}
par(mfrow = c(2, 3))
boxplot(cdi$CRM_1000, main = 'Crime Rate per 1000 people') # an obvious outlier around 300
boxplot(cdi$pop_den,main = 'Population Density')
boxplot(cdi$pop18, main = 'Percent of Population Aged 18-34')
boxplot(cdi$pop65, main = 'Percent of Population Aged 65+')
boxplot(cdi$pdocs, main = 'Per Capita Active Physicians')
boxplot(cdi$pbeds, main = 'Per Capita Hospital Beds')

```

```{r, dpi = 300}
par(mfrow = c(2,3))
boxplot(cdi$hsgrad, main = 'Percent High School Graduates')
boxplot(cdi$bagrad, main = 'Percent Bachelorâ€™s Degrees')
boxplot(cdi$poverty, main = 'Percent Below Poverty Level')
boxplot(cdi$unemp, main = 'Percent Unemployment')
boxplot(cdi$pcincome, main = 'Per Capita Income')
boxplot(cdi$totalinc, main = 'Total Personal Income')
```

## Marginal correlation with CRM_1000 of each variable

```{r, message = FALSE, dpi = 300}
cdi %>% ggplot(aes(x = pop_den, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pop18, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = pop65, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pdocs, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pbeds, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = hsgrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # negative correlation
cdi %>% ggplot(aes(x = bagrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = poverty, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = unemp, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pcincome, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = totalinc, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = region, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
```



## Identify counties with unusual crime rates.
```{r}
upper = quantile(cdi$CRM_1000, 0.75)
lower = quantile(cdi$CRM_1000, 0.25)
IQR = upper - lower

cdi %>% 
  filter(CRM_1000 > upper + 1.5*IQR,
         CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(cty, CRM_1000) %>%
  knitr::kable(digits = 2)
```


## Group by states and check for outliers again.
```{r}
cdi_state = 
  cdi %>% 
  group_by(state) %>% 
  summarise(state_pop = sum(pop),
            state_crimes = sum(crimes)) %>% 
  mutate(state_CRM_1000 = 1000*state_crimes/state_pop) %>% 
  relocate(state_CRM_1000)

cdi_state
```

```{r}
upper = quantile(cdi_state$state_CRM_1000, 0.75)
lower = quantile(cdi_state$state_CRM_1000, 0.25)
IQR = upper - lower

cdi_state %>% 
  filter(state_CRM_1000 > upper + 1.5*IQR,
         state_CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(state, state_CRM_1000) %>%
  knitr::kable(digits = 2)


boxplot(cdi_state$state_CRM_1000, main = 'State Crime Rate per 1000 people')
```
  
Surprisingly, if we look at the CRM_1000 at state level, no outliers were found.


## Remove Unnecessary Variables

```{r}
cdi = 
  cdi %>% 
  dplyr::select(-pop, -crimes, -cty)
```


## Check for Outliers and Influential Points

```{r}
mult.fit1 = lm(CRM_1000 ~ ., data = cdi) 

# residuals vs leverage plot
plot(mult.fit1, which = 4)

# remove influential points
cdiout = cdi[-c(6),]

# plot with and without influential points
plot(cdi$poverty, cdi$CRM_1000)
plot(cdiout$poverty, cdiout$CRM_1000)

# fit model with and without influential points
with = lm(CRM_1000 ~ ., data = cdi) 

without = lm(CRM_1000 ~ ., data = cdiout)

summary(with); summary(without) ##compare p values and r squared
```


## Check for transformation

```{r, dpi = 300}
mult.fit1 = lm(CRM_1000 ~ ., data = cdiout) 
summary(mult.fit1)

boxcox(mult.fit1)
```

Perform square root transformation because a is close to 1/2.

```{r, dpi = 300}
cdi_sqrt = 
  cdiout %>% 
  mutate(sqrt_CRM_1000 = sqrt(CRM_1000)) %>% 
  dplyr::select(-CRM_1000) %>% 
  relocate(sqrt_CRM_1000)

cdi_sqrt

mult.fit2 = lm(sqrt_CRM_1000 ~ ., data = cdi_sqrt) 

summary(mult.fit2)
boxcox(mult.fit2) 
```



## check for multicollinearity
```{r, dpi = 300}
cdi_cor = 
  cdi_sqrt %>%
  mutate(
    state = as.numeric(state),
    region = as.numeric(region)
  ) %>% 
  dplyr::select(-sqrt_CRM_1000)

pairs(cdi_cor)
# Correlation matrix for all variables
cor(cdi_cor) %>% 
  knitr::kable()

corrplot(cor(cdi_cor), 
         method = "color", 
         type = "upper",
         addCoef.col = "black", 
         number.cex = 0.6,
         diag = FALSE) 
```
 
## Model Selection

Fit a linear model after removing highly correlated variables.
```{r}
new_cdi =
  cdi_sqrt %>% 
  mutate(
    state = as.factor(state),
    region = as.factor(region)) %>% 
  dplyr::select(-state, -bagrad, -pdocs, -totalinc)

mult.fit = lm(sqrt_CRM_1000 ~ ., data = new_cdi)
summary(mult.fit)
```

Fit a linear model with interactions terms
```{r}
mult.fit_inter = lm(sqrt_CRM_1000 ~ pop18 + pop65 + hsgrad + poverty + unemp + pcincome + region + pop_den + pbeds + pop65 * region + poverty * region + pcincome * region, data = new_cdi)
summary(mult.fit_inter)
```


Backward Elimination

```{r}
# No pop65 * region
step1 = update(mult.fit_inter, . ~ . -pop65 * region)
summary(step1)

# No hsgrad
step2 = update(step1, . ~ . -hsgrad)
summary(step2)

# No pcincome * region
step3 = update(step2, . ~ . -pcincome * region)
summary(step3)

# No unemp
step4 = update(step3, . ~ . -unemp)
summary(step4)

multi_fit_back1 = lm(sqrt_CRM_1000 ~ pop18 + poverty + pop_den + pbeds + poverty * region, data = new_cdi)
summary(multi_fit_back1)
# multi_fit_back1: adjusted r squared is 0.4886

# just use one function for backward 
step(mult.fit_inter, direction = 'backward')

multi_fit_back2 = lm(sqrt_CRM_1000 ~ pop18 + poverty + unemp + pcincome + region + pop_den + pbeds + poverty * region, data = new_cdi)
summary(multi_fit_back2)

# multi_fit_back2: Adjusted R-squared is 0.5112 and AIC=146.56
```

Forward Selection

```{r}
step(mult.fit_inter, direction = 'forward')
multi_fit_forward = lm(sqrt_CRM_1000 ~ pop18 + pop65 + hsgrad + poverty + unemp + pcincome + region + pop_den + pbeds + pop65 * region + poverty * region + pcincome * region, data = new_cdi)
summary(multi_fit_forward)
# our Adjusted R-squared is 0.5168 and AIC=153.99
```

Use both selection
```{r}
step(mult.fit_inter, direction = 'both')

multi_fit_both = lm(sqrt_CRM_1000 ~ pop18 + poverty + unemp + pcincome + region + pop_den + pbeds + poverty * region + pcincome * region, data = new_cdi)
summary(multi_fit_both)
# our Adjusted R-squared is 0.5197 and AIC=146.56
```

Test based procedure
```{r, dpi = 300}
cdi_test = 
  new_cdi %>% 
  mutate(region = as.numeric(region))

mat = as.matrix(cdi_test)
# Printing the 2 best models of each size, using the Cp criterion:
leaps(x = mat[,2:10], y = mat[,1], nbest = 2, method = "Cp")


# Printing the 2 best models of each size, using the adjusted R^2 criterion:
leaps(x = mat[,2:10], y = mat[,1], nbest = 2, method = "adjr2")


# Function regsubsets() performs a subset selection by identifying the "best" model that contains
# a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better)
b = regsubsets(sqrt_CRM_1000 ~ ., data = cdi_test)
rs = summary(b)

# plot of Cp and Adj-R2 as functions of parameters
par(mfrow = c(1,2))

plot(2:9, rs$cp, xlab = "No of parameters", ylab = "Cp Statistic")
abline(0,1)

plot(2:9, rs$adjr2, xlab = "No of parameters", ylab = "Adj R2")


multi_fit_test = lm(sqrt_CRM_1000 ~ pop18 + hsgrad + poverty + pcincome + region + pop_den + pbeds + poverty * region, data = cdi_test)
summary(multi_fit_test)
#adjusted r squared = 0.483
```


## Model diagnostics

Diagnostic Plots for Backward Elimination 1
```{r,dpi=300}
par(mfrow = c(2,2))
plot(multi_fit_back1)
```

Diagnostic Plots for Backward Elimination 2
```{r,dpi=300}
par(mfrow = c(2,2))
plot(multi_fit_back2)
```

Diagnostic Plots for Forward Selection
```{r,dpi=300}
par(mfrow = c(2,2))
plot(multi_fit_forward)
```


Diagnostic Plots for Both Selection
```{r,dpi=300}
par(mfrow = c(2,2))
plot(multi_fit_both)
```


Diagnostic Plots for Test based procedure
```{r,dpi=300}
par(mfrow = c(2,2))
plot(multi_fit_test)
```


## Create a table comparing models
```{r}
stargazer::stargazer(multi_fit_back2, multi_fit_forward, multi_fit_test, type = "text", out = "table1.txt")
```






