---
title: "data_exploration"
author: "Weiheng Zhang"
date: "2021/11/28"
output: github_document
---

```{r message = FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(leaflet)
library(corrplot)
library(MASS)
library(performance)
library(leaps)


theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Data cleaning

```{r message = FALSE, warning = FALSE}
cdi =
  read_csv("./data/cdi.csv") %>% 
  mutate(
    cty = as.factor(cty),
    state = as.factor(state),
    region = factor(region, levels = c("1", "2", "3", "4"),
                    labels = c("Northeast", "North_Central", "South", "West")),
    CRM_1000 = 1000*crimes/pop,
    pop_den = pop/area,
    pdocs = docs/pop,
    pbeds = beds/pop) %>%
  dplyr::select(-id, -area, -beds, -docs) %>%  # pop and crimes will be removed after detecting state outliers.
  relocate(CRM_1000)

cdi
```

## Descriptive Statistics.
```{r}
summary(cdi)
```

```{r}
sapply(cdi, function(x) sum(is.na(x)))

map(cdi, ~sum(is.na(.)))
```
No missing values were found.

## Boxplot for each variable

```{r, dpi = 300}
par(mfrow = c(2, 3))
boxplot(cdi$CRM_1000, main = 'Crime Rate per 1000 people') # an obvious outlier around 300
boxplot(cdi$pop_den,main = 'Population Density')
boxplot(cdi$pop18, main = 'Percent of Population Aged 18-34')
boxplot(cdi$pop65, main = 'Percent of Population Aged 65+')
boxplot(cdi$pdocs, main = 'Per Capita Active Physicians')
boxplot(cdi$pbeds, main = 'Per Capita Hospital Beds')

```

```{r, dpi = 300}
par(mfrow = c(2,3))
boxplot(cdi$hsgrad, main = 'Percent High School Graduates')
boxplot(cdi$bagrad, main = 'Percent Bachelor’s Degrees')
boxplot(cdi$poverty, main = 'Percent Below Poverty Level')
boxplot(cdi$unemp, main = 'Percent Unemployment')
boxplot(cdi$pcincome, main = 'Per Capita Income')
boxplot(cdi$totalinc, main = 'Total Personal Income')
```

## Marginal correlation with CRM_1000 of each variable

```{r, message = FALSE, dpi = 300}
cdi %>% ggplot(aes(x = pop_den, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pop18, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = pop65, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pdocs, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pbeds, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = hsgrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') #negative correlation
cdi %>% ggplot(aes(x = bagrad, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = poverty, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red') # positive correlation
cdi %>% ggplot(aes(x = unemp, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = pcincome, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = totalinc, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
cdi %>% ggplot(aes(x = region, y = CRM_1000)) + geom_point(alpha = 0.3) + geom_smooth(method = 'lm', se = TRUE, color = 'red')
```

## Identify counties with unusual crime rates.
```{r}
upper = quantile(cdi$CRM_1000, 0.75)
lower = quantile(cdi$CRM_1000, 0.25)
IQR = upper - lower

cdi %>% 
  filter(CRM_1000 > upper + 1.5*IQR,
         CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(cty, CRM_1000) %>%
  knitr::kable(digits = 2)
```


## Group by states and check for outliers again.
```{r}
cdi_state = 
  cdi %>% 
  group_by(state) %>% 
  summarise(state_pop = sum(pop),
            state_crimes = sum(crimes)) %>% 
  mutate(state_CRM_1000 = 1000*state_crimes/state_pop) %>% 
  relocate(state_CRM_1000)

cdi_state
```

```{r}
upper = quantile(cdi_state$state_CRM_1000, 0.75)
lower = quantile(cdi_state$state_CRM_1000, 0.25)
IQR = upper - lower

cdi_state %>% 
  filter(state_CRM_1000 > upper + 1.5*IQR,
         state_CRM_1000 > lower - 1.5*IQR) %>% 
  dplyr::select(state, state_CRM_1000) %>%
  knitr::kable(digits = 2)


boxplot(cdi_state$state_CRM_1000, main = 'State Crime Rate per 1000 people')
```
  
Surprisingly, if we look at the CRM_1000 at state level, no outlier was found.


## Remove Unnecessary Variables

```{r}
cdi = 
  cdi %>% 
  dplyr::select(-pop, -crimes, -cty)
```


## Checking to Outliers and Influential Points

```{r}

mult.fit1 = lm(CRM_1000 ~ ., data = cdi) 

# residuals vs leverage plot
plot(mult.fit1, which = 4)

# remove influential points
cdiout = cdi[-c(6),]

# plot with and without influential points
plot(cdi$poverty, cdi$CRM_1000)
plot(cdiout$poverty, cdiout$CRM_1000)

# fit model with and without influential points
with = lm(CRM_1000 ~ ., data = cdi) 

without = lm(CRM_1000 ~ ., data = cdiout)

summary(with); summary(without) ##compare p values and r squared
```



## Check for transformation

```{r}
# fit multivariate model
mult.fit1 = lm(CRM_1000 ~ ., data = cdiout) 
summary(mult.fit1)

boxcox(mult.fit1)
```


## a is close to 1/2. Perform sqrt transformation.

```{r}
cdi_sqrt = 
  cdiout %>% 
  mutate(sqrt_CRM_1000 = sqrt(CRM_1000)) %>% 
  dplyr::select(-CRM_1000) %>% 
  relocate(sqrt_CRM_1000)

cdi_sqrt

mult.fit2 = lm(sqrt_CRM_1000 ~ ., data = cdi_sqrt) 

summary(mult.fit2) ##region returned NA, why?
boxcox(mult.fit2) 
```



## check for multicollinearity
```{r, dpi = 300}
cdi_cor = 
  cdi_sqrt %>%
  mutate(
    state = as.numeric(state),
    region = as.numeric(region)
  ) %>% 
  dplyr::select(-sqrt_CRM_1000)

pairs(cdi_cor)
# Correlation matrix for all variables
cor(cdi_cor) %>% 
  knitr::kable()

corrplot(cor(cdi_cor), type = "upper", diag = FALSE)
```
 
## Model Selection

Fit a linear model after removing highly correlated variables.
```{r}
new_cdi =
  cdi_sqrt %>% 
  mutate(
    state = as.factor(state),
    region = as.factor(region)) %>% 
  dplyr::select(-hsgrad, -pcincome)

mult.fit = lm(sqrt_CRM_1000 ~ ., data = new_cdi)
summary(mult.fit)

#不确定是否加interaction
#mult.fit_inter = lm(sqrt_CRM_1000 ~ state + pop18 + grad + pcincome + hsgrad + pop65 + bagrad + #poverty + unemp + totalinc + region + pop_den + pbeds + hsgrad*bagrad + hsgrad*poverty + #pop18*pop65 + bagrad*pcincome + pbeds*pdocs, data = new_cdi)
#summary(mult.fit_new)
```

Backward Elimination

```{r}
# No region, becasue the original mulitiple linear fit, the region has NA
step1 = update(mult.fit, . ~ . -region)
summary(step1)

# No state 
step2 = update(step1, . ~ . -state)
summary(step2)

# No pop65
step3 = update(step2, . ~ . -pop65)
summary(step3)

# No pdocs
step4 = update(step3, . ~ . -pdocs)
summary(step4)

# No pop18
step5 = update(step4, . ~ . -pop18)
summary(step5)

multi_fit_back1 = lm(sqrt_CRM_1000 ~ bagrad + poverty + unemp + totalinc + 
    pop_den + pbeds, data = new_cdi)
summary(multi_fit_back1)
# multi_fit1: adjusted r squared is 0.3431, 

# just use one function for backward 
step(mult.fit, direction = 'backward')

multi_fit_back2 = lm(sqrt_CRM_1000 ~ state + pop18 + poverty + totalinc + 
    pop_den + pbeds, data = new_cdi)

summary(multi_fit_back2)
# multi_fit2: Adjusted R-squared is 0.5808 and AIC=120.61
```


Forward Selection

```{r}
step(mult.fit, direction = 'forward')
multi_fit_forward = lm(sqrt_CRM_1000 ~ state + pop18 + pop65 + bagrad + poverty + unemp + totalinc + region + pop_den + pdocs + pbeds, data = new_cdi)
summary(multi_fit_forward)
# our Adjusted R-squared is 0.5789 and AIC=126.05
```

use both selection

```{r}
step(mult.fit, direction = 'both')
multi_fit_both = lm(sqrt_CRM_1000 ~ state + pop18 + poverty + totalinc + 
    pop_den + pbeds, data = new_cdi)
summary(multi_fit_both)
# our Adjusted R-squared is 0.5808 and AIC=120.61
```


```{r}
#```{r}
##Step 1:  Fit simple linear regressions for all variables,look for the variable with lowest p-value
#fit1 = lm(sqrt_CRM_1000 ~ state, data = new_cdi)
#summary(fit1) 
#fit2 = lm(sqrt_CRM_1000 ~ region, data = new_cdi)
#summary(fit2) 
#fit3 = lm(sqrt_CRM_1000 ~ totalinc, data = new_cdi)
#summary(fit3) 
#fit4 = lm(sqrt_CRM_1000 ~ pop18, data = new_cdi)
#summary(fit4)
#fit5 = lm(sqrt_CRM_1000 ~ pop65, data = new_cdi)
#summary(fit5) 
#fit6 = lm(sqrt_CRM_1000 ~ pdocs, data = new_cdi)
#summary(fit6) 
#fit7 = lm(sqrt_CRM_1000 ~ pbeds, data = new_cdi)
#summary(fit7) 
#fit8 = lm(sqrt_CRM_1000 ~ bagrad, data = new_cdi)
#summary(fit8) 
#fit9 = lm(sqrt_CRM_1000 ~ poverty, data = new_cdi)
#summary(fit9) 
#fit10 = lm(sqrt_CRM_1000 ~ unemp, data = new_cdi)
#summary(fit10) 
#fit11 = lm(sqrt_CRM_1000 ~ pop_den, data = new_cdi)
#summary(fit11) 
#
#
#
## Enter first the one with the lowest p-value: poverty
#forward1 = lm(sqrt_CRM_1000 ~ poverty, data = new_cdi)
#summary(forward1)
#
#### Step 2: Enter the one with the lowest p-value in the rest 
#fit1 = update(forward1, . ~ . +state)
#summary(fit1)
#fit2 = update(forward1, . ~ . +region)
#summary(fit2)
#fit3 = update(forward1, . ~ . +totalinc)
#summary(fit3)
#fit4 = update(forward1, . ~ . +pop18)
#summary(fit4)
#fit5 = update(forward1, . ~ . +pop65)
#summary(fit5)
#fit6 = update(forward1, . ~ . +pdocs)
#summary(fit6)
#fit7 = update(forward1, . ~ . +pbeds)
#summary(fit7)
#fit8 = update(forward1, . ~ . +bagrad)
#summary(fit8)
#fit9 = update(forward1, . ~ . +unemp)
#summary(fit9)
#fit10 = update(forward1, . ~ . +pop_den)
#summary(fit10) 
#
#
#
## Enter the one with the lowest p-value: beds
#forward2 = update(forward1, . ~ . + beds)
#summary(forward2)
#
#### Step 3: Enter the one with the lowest p-value in the rest 
#fit1 = update(forward2, . ~ . +state)
#summary(fit1)
#fit2 = update(forward2, . ~ . +area)
#summary(fit2)
#fit3 = update(forward2, . ~ . +pop)
#summary(fit3)
#fit4 = update(forward2, . ~ . +pop18)
#summary(fit4)
#fit5 = update(forward2, . ~ . +pop65)
#summary(fit5)
#fit6 = update(forward2, . ~ . +docs)
#summary(fit6)
#fit7 = update(forward2, . ~ . +hsgrad)
#summary(fit7)
#fit8 = update(forward2, . ~ . +bagrad)
#summary(fit8)
#fit9 = update(forward2, . ~ . +unemp)
#summary(fit9)
#fit10 = update(forward2, . ~ . +pcincome)
#summary(fit10)
#fit11 = update(forward2, . ~ . +totalinc)
#summary(fit11)
#
#
## Enter the one with the lowest p-value: bagrad
#forward3 = update(forward2, . ~ . + bagrad)
#summary(forward3)
#
#### Step 4: Enter the one with the lowest p-value in the rest 
#fit1 = update(forward2, . ~ . +state)
#summary(fit1)
#fit2 = update(forward2, . ~ . +area)
#summary(fit2)
#fit3 = update(forward2, . ~ . +pop)
#summary(fit3)
#fit4 = update(forward2, . ~ . +pop18)
#summary(fit4)
#fit5 = update(forward2, . ~ . +pop65)
#summary(fit5)
#fit6 = update(forward2, . ~ . +docs)
#summary(fit6)
#fit7 = update(forward2, . ~ . +hsgrad)
#summary(fit7)
#fit8 = update(forward2, . ~ . +unemp)
#summary(fit8)
#fit9 = update(forward2, . ~ . +pcincome)
#summary(fit9)
#fit10 = update(forward2, . ~ . +totalinc)
#summary(fit10)
#
#
## Enter the one with the lowest p-value: unemp
#forward4 = update(forward3, . ~ . + unemp)
#summary(forward4)
#
#
#### Step 5: Enter the one with the lowest p-value in the rest 
#fit1 = update(forward2, . ~ . +state)
#summary(fit1)
#fit2 = update(forward2, . ~ . +area)
#summary(fit2)
#fit3 = update(forward2, . ~ . +pop)
#summary(fit3)
#fit4 = update(forward2, . ~ . +pop18)
#summary(fit4)
#fit5 = update(forward2, . ~ . +pop65)
#summary(fit5)
#fit6 = update(forward2, . ~ . +docs)
#summary(fit6)
#fit7 = update(forward2, . ~ . +hsgrad)
#summary(fit7)
#fit8 = update(forward2, . ~ . +pcincome)
#summary(fit8)
#fit9 = update(forward2, . ~ . +totalinc)
#summary(fit9)
#
## Enter the one with the lowest p-value: pop18
#
#forward5 = update(forward4, . ~ . + pop18)
#summary(forward5)
```

Test based procedure

```{r}
mat = as.matrix(new_cdi)
# Printing the 2 best models of each size, using the Cp criterion:
leaps(x = mat[,2:12], y = mat[,1], nbest = 2, method = "Cp")

# Printing the 2 best models of each size, using the adjusted R^2 criterion:
leaps(x = mat[,2:12], y = mat[,1], nbest = 2, method = "adjr2")


# Function regsubsets() performs a subset selection by identifying the "best" model that contains
# a certain number of predictors. By default "best" is chosen using SSE/RSS (smaller is better)
b = regsubsets(sqrt_CRM_1000 ~ ., data = new_cdi)
rs = summary(b)

# plot of Cp and Adj-R2 as functions of parameters
par(mfrow = c(1,2))

plot(2:9, rs$cp, xlab = "No of parameters", ylab = "Cp Statistic")
abline(0,1)

plot(2:9, rs$adjr2, xlab = "No of parameters", ylab = "Adj R2")
```








